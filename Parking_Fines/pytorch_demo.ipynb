{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Neural Networks Demo - NYC Parking Fines\n",
    "\n",
    "This notebook demonstrates how to use the PyTorch neural network models for parking fines prediction.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "1. Install PyTorch dependencies: `pip install -r requirements_pytorch.txt`\n",
    "2. Train the models: `python train_pytorch_model.py`\n",
    "\n",
    "This will create trained models in the `models/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pytorch_model import FineAmountRegressor, FineCategoryClassifier\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessor\n",
    "with open('models/preprocessor.pkl', 'rb') as f:\n",
    "    preprocessor = pickle.load(f)\n",
    "print(\"✓ Preprocessor loaded\")\n",
    "\n",
    "# Load regression model\n",
    "reg_checkpoint = torch.load('models/pytorch_regressor.pth', map_location='cpu')\n",
    "reg_model = FineAmountRegressor(input_dim=reg_checkpoint['input_dim'])\n",
    "reg_model.load_state_dict(reg_checkpoint['model_state_dict'])\n",
    "reg_model.eval()\n",
    "print(\"\\n✓ Regression model loaded\")\n",
    "print(f\"  MAE: {reg_checkpoint['metrics']['mae']:.2f}\")\n",
    "print(f\"  RMSE: {reg_checkpoint['metrics']['rmse']:.2f}\")\n",
    "print(f\"  R²: {reg_checkpoint['metrics']['r2']:.4f}\")\n",
    "\n",
    "# Load classification model\n",
    "class_checkpoint = torch.load('models/pytorch_classifier.pth', map_location='cpu')\n",
    "class_model = FineCategoryClassifier(\n",
    "    input_dim=class_checkpoint['input_dim'],\n",
    "    num_classes=class_checkpoint['num_classes']\n",
    ")\n",
    "class_model.load_state_dict(class_checkpoint['model_state_dict'])\n",
    "class_model.eval()\n",
    "label_encoder = class_checkpoint['label_encoder']\n",
    "print(\"\\n✓ Classification model loaded\")\n",
    "print(f\"  Accuracy: {class_checkpoint['metrics']['accuracy']:.4f}\")\n",
    "print(f\"  F1 Score (macro): {class_checkpoint['metrics']['f1_macro']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data\n",
    "\n",
    "Let's create some example parking violations to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parking violations\n",
    "sample_data = pd.DataFrame({\n",
    "    'Registration State': ['NY', 'NJ', 'NY', 'PA', 'CT'],\n",
    "    'Plate Type': ['PAS', 'PAS', 'COM', 'PAS', 'PAS'],\n",
    "    'Vehicle Body Type': ['SUBN', 'SDN', 'VAN', 'SDN', 'SUBN'],\n",
    "    'Vehicle Make': ['TOYOTA', 'HONDA', 'FORD', 'CHEVR', 'BMW'],\n",
    "    'Violation County': ['NY', 'NY', 'BX', 'K', 'NY'],\n",
    "    'Violation In Front Of Or Opposite': ['F', 'O', 'F', 'F', 'O'],\n",
    "    'Plate ID': ['ABC1234', 'XYZ5678', 'COM999', 'TEST123', 'BMW456'],\n",
    "    'Vehicle Expiration_year': [2015, 2016, 2015, 2015, 2016],\n",
    "    'Vehicle Expiration_month': [12, 6, 9, 3, 8],\n",
    "    'Vehicle Expiration_day': [31, 15, 1, 20, 15],\n",
    "    'Vehicle Year': [2012, 2010, 2008, 2013, 2014],\n",
    "    'Hour_sin': [0.5, 0.866, -0.5, 0.0, 0.707],\n",
    "    'Hour_cos': [0.866, 0.5, 0.866, 1.0, 0.707],\n",
    "    'Issue Date_year': [2015, 2015, 2015, 2015, 2015],\n",
    "    'Issue Date_month': [5, 5, 6, 4, 7],\n",
    "    'Issue Date_day': [15, 20, 1, 10, 4]\n",
    "})\n",
    "\n",
    "print(\"Sample parking violations:\")\n",
    "sample_data[['Registration State', 'Vehicle Make', 'Vehicle Body Type', 'Violation County']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features\n",
    "X_processed = preprocessor.transform(sample_data)\n",
    "X_tensor = torch.FloatTensor(X_processed)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    # Regression: predict fine amount\n",
    "    fine_amounts = reg_model(X_tensor).numpy()\n",
    "    \n",
    "    # Classification: predict fine category\n",
    "    class_outputs = class_model(X_tensor)\n",
    "    _, class_indices = torch.max(class_outputs, 1)\n",
    "    fine_categories = label_encoder.inverse_transform(class_indices.numpy())\n",
    "\n",
    "# Add predictions to dataframe\n",
    "sample_data['Predicted_Fine_Amount'] = fine_amounts.round(2)\n",
    "sample_data['Predicted_Fine_Category'] = fine_categories\n",
    "\n",
    "# Display results\n",
    "results_display = sample_data[[\n",
    "    'Registration State', 'Vehicle Make', 'Vehicle Body Type',\n",
    "    'Predicted_Fine_Amount', 'Predicted_Fine_Category'\n",
    "]]\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(results_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted fine amounts\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(sample_data)), sample_data['Predicted_Fine_Amount'])\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted Fine Amount ($)')\n",
    "plt.title('Predicted Fine Amounts')\n",
    "plt.xticks(range(len(sample_data)))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "category_counts = sample_data['Predicted_Fine_Category'].value_counts()\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.xlabel('Fine Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Predicted Fine Categories')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Let's examine the neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression Model Architecture:\")\n",
    "print(\"=\"*50)\n",
    "print(reg_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in reg_model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in reg_model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Model Architecture:\")\n",
    "print(\"=\"*50)\n",
    "print(class_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in class_model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in class_model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History\n",
    "\n",
    "Visualize the training and validation loss over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for regression model\n",
    "if 'history' in reg_checkpoint:\n",
    "    history = reg_checkpoint['history']\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_losses'], label='Train Loss')\n",
    "    plt.plot(history['val_losses'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.title('Regression Model Training History')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot for classification model\n",
    "    if 'history' in class_checkpoint:\n",
    "        class_history = class_checkpoint['history']\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(class_history['train_losses'], label='Train Loss')\n",
    "        plt.plot(class_history['val_losses'], label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss (CrossEntropy)')\n",
    "        plt.title('Classification Model Training History')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Training history not available in checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPrediction Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Average predicted fine: ${sample_data['Predicted_Fine_Amount'].mean():.2f}\")\n",
    "print(f\"Minimum predicted fine: ${sample_data['Predicted_Fine_Amount'].min():.2f}\")\n",
    "print(f\"Maximum predicted fine: ${sample_data['Predicted_Fine_Amount'].max():.2f}\")\n",
    "print(f\"Std deviation: ${sample_data['Predicted_Fine_Amount'].std():.2f}\")\n",
    "\n",
    "print(\"\\nCategory Distribution:\")\n",
    "print(sample_data['Predicted_Fine_Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Metrics\n",
    "\n",
    "Compare with other models from the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['PyTorch Neural Network', 'Linear Regression', 'Random Forest', 'XGBoost'],\n",
    "    'MAE': [reg_checkpoint['metrics']['mae'], 'Run notebook to compare', '', ''],\n",
    "    'RMSE': [reg_checkpoint['metrics']['rmse'], 'Run notebook to compare', '', ''],\n",
    "    'R²': [f\"{reg_checkpoint['metrics']['r2']:.4f}\", 'Run notebook to compare', '', '']\n",
    "})\n",
    "\n",
    "print(\"\\nRegression Model Comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nClassification Model Performance:\")\n",
    "print(f\"Accuracy: {class_checkpoint['metrics']['accuracy']:.4f}\")\n",
    "print(f\"F1 Score (macro): {class_checkpoint['metrics']['f1_macro']:.4f}\")\n",
    "print(\"\\nTo compare with XGBoost, run the main nyc_fines.ipynb notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading trained PyTorch models\n",
    "2. Making predictions on new data\n",
    "3. Visualizing results\n",
    "4. Examining model architecture\n",
    "5. Viewing training history\n",
    "\n",
    "### Next Steps:\n",
    "- Compare these results with models in `nyc_fines.ipynb`\n",
    "- Experiment with different architectures\n",
    "- Try hyperparameter tuning\n",
    "- Use the models for production predictions\n",
    "\n",
    "### Documentation:\n",
    "See `pytorch_model_readme.md` for detailed documentation and usage instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
